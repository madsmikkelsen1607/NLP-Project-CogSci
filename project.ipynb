{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296bb5e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01159056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6da665",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 78.4 MiB for an array with shape (5134856,) and data type complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Loading in genius lyrics data from Hugging face: https://huggingface.co/datasets/sebastiandizon/genius-song-lyrics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m raw_genius_lyrics = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhf://datasets/sebastiandizon/genius-song-lyrics/song_lyrics 2.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1965\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1966\u001b[39m         new_col_dict = col_dict\n\u001b[32m-> \u001b[39m\u001b[32m1968\u001b[39m     df = \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1975\u001b[39m     \u001b[38;5;28mself\u001b[39m._currow += new_rows\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    776\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    777\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    778\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     arrays, refs = \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \n\u001b[32m    126\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    127\u001b[39m     index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[39m, in \u001b[36m_homogenize\u001b[39m\u001b[34m(data, index, dtype)\u001b[39m\n\u001b[32m    626\u001b[39m         val = \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[32m    627\u001b[39m     val = lib.fast_multiget(val, oindex._values, default=np.nan)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m val = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m com.require_length_match(val, index)\n\u001b[32m    631\u001b[39m refs.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\core\\construction.py:604\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, allow_2d)\u001b[39m\n\u001b[32m    602\u001b[39m subarr = data\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     subarr = \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    605\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m object_index \u001b[38;5;129;01mand\u001b[39;00m using_string_dtype() \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr):\n\u001b[32m    606\u001b[39m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[32m    607\u001b[39m         subarr = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1200\u001b[39m, in \u001b[36mmaybe_infer_to_datetimelike\u001b[39m\u001b[34m(value, convert_to_nullable_dtype)\u001b[39m\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m   1197\u001b[39m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[32m   1198\u001b[39m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[32m   1199\u001b[39m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   1201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[32m   1203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[32m   1204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_non_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mM8[ns]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2556\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_objects\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 78.4 MiB for an array with shape (5134856,) and data type complex128"
     ]
    }
   ],
   "source": [
    "#Loading in genius lyrics data from Hugging face: https://huggingface.co/datasets/sebastiandizon/genius-song-lyrics\n",
    "raw_genius_lyrics = pd.read_csv(\"hf://datasets/sebastiandizon/genius-song-lyrics/song_lyrics 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               title  tag     artist  year   views  \\\n",
      "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
      "1         Can I Live  rap      JAY-Z  1996  468624   \n",
      "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
      "3       Down and Out  rap    Cam'ron  2004  144404   \n",
      "4             Fly In  rap  Lil Wayne  2005   78271   \n",
      "\n",
      "                                       features  \\\n",
      "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
      "1                                            {}   \n",
      "2                                            {}   \n",
      "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
      "4                                            {}   \n",
      "\n",
      "                                              lyrics  id language_cld3  \\\n",
      "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
      "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
      "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
      "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
      "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
      "\n",
      "  language_ft language  \n",
      "0          en       en  \n",
      "1          en       en  \n",
      "2          en       en  \n",
      "3          en       en  \n",
      "4          en       en  \n"
     ]
    }
   ],
   "source": [
    "print(raw_genius_lyrics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d90533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viggo\\Documents\\Cognitive Science Masters\\1st. semester\\Natural Language Processing\\NLP_exam_project\\NLP-Project-CogSci\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'tag', 'artist', 'year', 'views', 'features', 'lyrics', 'id', 'language_cld3', 'language_ft', 'language']\n"
     ]
    }
   ],
   "source": [
    "data_columns = raw_genius_lyrics.columns.tolist()\n",
    "print(data_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
